{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FapHiYvyoGNE"
   },
   "source": [
    "# Fetch 'daylight' data\n",
    "\n",
    "_Primary Author: Peter King_\n",
    "\n",
    "This notebook generates a pandas DataFrame showing daylight hours on the Winter Solstice in calendar year 2022 (21 Dec 2022) for the 50 U.S. states, plus Puerto Rico and Washington, D.C.  We will use this dataset in combination with data from the Behavioral Risk Factor Surveillance System (BRFSS) 2022, in order to investigate correlation between daylight hours in winter (as occurs in the northern latitudes in the northern hemisphere) with self-reported feelings of depression, as measure by a novel \"depression index\" (DI).\n",
    "\n",
    "## Methodology\n",
    "\n",
    "We start by using the 'requests' library to fetch two plain text files that contain a list of states and territories, along with their capitals and associated latitudes and longitudes.  We then feed the latitudes and longitudes for the capitals into the U.S. Naval Observatory's (USNO) [Application Programming Interface](https://aa.usno.navy.mil/data/api) (API), to get sunrise and sunset times on the Winter Solstice for each geographic location.  Finally, we take the difference between sunset and sunrise to be the number of daylight hours available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R2E3ZugxaIsI"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PATH = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEBhbLBLwKOo"
   },
   "source": [
    "## Data wrangling -- Dealing with plain text data\n",
    "\n",
    "We first get a list of all 50 states, their capitals, and the lat/long of each capital.  We start by requesting raw data in the form of two text files.\n",
    "\n",
    "In order to process the data in the text files, we first split each file on the newline character ('\\\\n'), and we then use a regular expression to parse each line to catpure four fields of interest: the state code, capital name, latitude, and longitude.  We capture information for each state in a set of pandas Series objects and then compile these into a DataFrame.  Pandas' indexing capability ensures consistency in data organization and facilitates joining this dataset with our primary dataset, the BRFSS 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1738354656519,
     "user": {
      "displayName": "Peter King",
      "userId": "04189723304750020218"
     },
     "user_tz": 300
    },
    "id": "rFGydeWNk_wI",
    "outputId": "cba36f25-8af6-41c4-946c-9d927b1084cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capital</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Montgomery</td>\n",
       "      <td>32.361538</td>\n",
       "      <td>-86.279118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Juneau</td>\n",
       "      <td>58.301935</td>\n",
       "      <td>-134.419740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>33.448457</td>\n",
       "      <td>-112.073844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>34.736009</td>\n",
       "      <td>-92.331122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>38.555605</td>\n",
       "      <td>-121.468926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Capital        Lat         Long\n",
       "AL   Montgomery  32.361538   -86.279118\n",
       "AK       Juneau  58.301935  -134.419740\n",
       "AZ      Phoenix  33.448457  -112.073844\n",
       "AR  Little Rock  34.736009   -92.331122\n",
       "CA   Sacramento  38.555605  -121.468926"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Request data\n",
    "URL_capital = 'https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_name.txt'\n",
    "URL_lat_long = 'https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt'\n",
    "capital_data = requests.get(URL_capital)\n",
    "lat_long_data = requests.get(URL_lat_long)\n",
    "\n",
    "## Convert raw text data from URL request into pandas DataFrame\n",
    "\n",
    "# Split on newline to create python lists\n",
    "st_cap_list = capital_data.text.split('\\n')\n",
    "st_ll_list = lat_long_data.text.split('\\n')\n",
    "st_ll_list.pop()  # for some reason there is a dangling empty string\n",
    "\n",
    "# For each list, create a pandas Series\n",
    "state, capital = [], []\n",
    "for row in st_cap_list:\n",
    "    element = row.split('  ')\n",
    "    state.append(element[0])\n",
    "    capital.append(element[1].strip('\"'))\n",
    "capital_Ser = pd.Series(data=capital, index=state, name='Capital')\n",
    "\n",
    "# Use a regular expression to convert each row of free text to a list of values\n",
    "value = re.compile('[A-Z.0-9\\-]+')\n",
    "state, lat, long = [], [], []\n",
    "for row in st_ll_list:\n",
    "    element = value.findall(row)\n",
    "    state.append(element[0])\n",
    "    lat.append(element[1])\n",
    "    long.append(element[2])\n",
    "lat_Ser = pd.Series(data=lat, index=state, name='Lat')\n",
    "long_Ser = pd.Series(data=long, index=state, name='Long')\n",
    "\n",
    "# Assemble Series into DataFrame\n",
    "geo_df = pd.DataFrame([capital_Ser, lat_Ser, long_Ser]).T\n",
    "# Drop duplicated row for Washington, DC\n",
    "geo_df.drop('US', inplace=True)\n",
    "\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738354656519,
     "user": {
      "displayName": "Peter King",
      "userId": "04189723304750020218"
     },
     "user_tz": 300
    },
    "id": "PJ8h1Gbhr0n7",
    "outputId": "d717f085-a4b4-49df-b40d-9e9696c00786"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geo_df.index) # Includes 50 states + Puerto Rico (PR) and Distric of Columbia (DC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igzki-R1usSU"
   },
   "source": [
    "## Data Wrangling -- Working with the USNO API\n",
    "\n",
    "The [USNO API](https://aa.usno.navy.mil/data/api) returns sunrise/sunset data in JSON format, so here we use the 'json' standard module to facilitate information capture.  Sunrise and sunset times are provided as strings, so we use the 'datetime' standard module to convert these to Python's 'datetime' data type.  Using this data type makes it easy to calculate daylight hours as a simple difference: daylight = sunset - sunrise.\n",
    "\n",
    "We again use a pandas Series to capture the information for each state, and then we compile them into a DataFrame.\n",
    "\n",
    "Note: Since the terms of use for the USNO API limits query frequency to 1 query per second, we use 'time' standard module to enforce a 1 second delay between queries in our 'for' loop.  **This code block will take a ~2 minutes to run due to the enforced time delay.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OJocq0MhcTG8"
   },
   "outputs": [],
   "source": [
    "### Use data from geo_df to make a separate DataFrame for Daylight information\n",
    "\n",
    "## For each state, query the USNO API for Sunrise/Sunset Data\n",
    "date = '2022-12-21'\n",
    "daylight = []\n",
    "for state in geo_df.index:\n",
    "    URL = ('https://aa.usno.navy.mil/api/rstt/oneday?date=2022-12-21&coords='\n",
    "           + geo_df['Lat'].loc[state] + ',' + geo_df['Long'].loc[state]\n",
    "           + '&tz=-8&dst=false'\n",
    "          )\n",
    "    response = requests.get(URL)\n",
    "    # Convert response data to json and then to pandas Series\n",
    "    data_json = json.loads(response.text)\n",
    "    index = [data_json['properties']['data']['sundata'][i]['phen'] for i in range(5)]\n",
    "    data = [pd.to_datetime(date + ' ' + data_json['properties']['data']['sundata'][i]['time']) for i in range(5)]\n",
    "    row = pd.Series(data=data, index=index, name=state)\n",
    "    # Add a column for Daylight Hours as the difference between Sunset and Sunrise\n",
    "    row['Daylight Hours'] = row['Set'] - row['Rise']\n",
    "    daylight.append(row)\n",
    "    # Free API access is limited to one query per second\n",
    "    time.sleep(1)\n",
    "\n",
    "daylight_df = pd.DataFrame(daylight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738354733032,
     "user": {
      "displayName": "Peter King",
      "userId": "04189723304750020218"
     },
     "user_tz": 300
    },
    "id": "k9ttfaccazIr",
    "outputId": "109605f5-a4c4-4bd9-e22d-ab2c873d963b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Begin Civil Twilight</th>\n",
       "      <th>Rise</th>\n",
       "      <th>Upper Transit</th>\n",
       "      <th>Set</th>\n",
       "      <th>End Civil Twilight</th>\n",
       "      <th>Daylight Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>2022-12-21 04:15:00</td>\n",
       "      <td>2022-12-21 04:42:00</td>\n",
       "      <td>2022-12-21 09:43:00</td>\n",
       "      <td>2022-12-21 14:44:00</td>\n",
       "      <td>2022-12-21 15:11:00</td>\n",
       "      <td>0 days 10:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>2022-12-21 08:52:00</td>\n",
       "      <td>2022-12-21 09:45:00</td>\n",
       "      <td>2022-12-21 12:56:00</td>\n",
       "      <td>2022-12-21 16:07:00</td>\n",
       "      <td>2022-12-21 17:00:00</td>\n",
       "      <td>0 days 06:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>2022-12-21 06:01:00</td>\n",
       "      <td>2022-12-21 06:28:00</td>\n",
       "      <td>2022-12-21 11:26:00</td>\n",
       "      <td>2022-12-21 16:25:00</td>\n",
       "      <td>2022-12-21 16:52:00</td>\n",
       "      <td>0 days 09:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>2022-12-21 04:45:00</td>\n",
       "      <td>2022-12-21 05:13:00</td>\n",
       "      <td>2022-12-21 10:07:00</td>\n",
       "      <td>2022-12-21 15:02:00</td>\n",
       "      <td>2022-12-21 15:30:00</td>\n",
       "      <td>0 days 09:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2022-12-21 06:50:00</td>\n",
       "      <td>2022-12-21 07:20:00</td>\n",
       "      <td>2022-12-21 12:04:00</td>\n",
       "      <td>2022-12-21 16:48:00</td>\n",
       "      <td>2022-12-21 17:18:00</td>\n",
       "      <td>0 days 09:28:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Begin Civil Twilight                Rise       Upper Transit  \\\n",
       "AL  2022-12-21 04:15:00 2022-12-21 04:42:00 2022-12-21 09:43:00   \n",
       "AK  2022-12-21 08:52:00 2022-12-21 09:45:00 2022-12-21 12:56:00   \n",
       "AZ  2022-12-21 06:01:00 2022-12-21 06:28:00 2022-12-21 11:26:00   \n",
       "AR  2022-12-21 04:45:00 2022-12-21 05:13:00 2022-12-21 10:07:00   \n",
       "CA  2022-12-21 06:50:00 2022-12-21 07:20:00 2022-12-21 12:04:00   \n",
       "\n",
       "                   Set  End Civil Twilight  Daylight Hours  \n",
       "AL 2022-12-21 14:44:00 2022-12-21 15:11:00 0 days 10:02:00  \n",
       "AK 2022-12-21 16:07:00 2022-12-21 17:00:00 0 days 06:22:00  \n",
       "AZ 2022-12-21 16:25:00 2022-12-21 16:52:00 0 days 09:57:00  \n",
       "AR 2022-12-21 15:02:00 2022-12-21 15:30:00 0 days 09:49:00  \n",
       "CA 2022-12-21 16:48:00 2022-12-21 17:18:00 0 days 09:28:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daylight_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP5qxy0yybIw"
   },
   "source": [
    "Finally, we save our final 'daylight' DataFrame to disk as a CSV file in order to access it more easily in the analysis and visualization notebooks associated with this project.  Note that we developed our code in Google's Colab environment.  Since our project needs to function in the Jupyter environment provided for SIADS 593 via Coursera, we provided a second option for the PATH string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "error",
     "timestamp": 1739276842798,
     "user": {
      "displayName": "Peter King",
      "userId": "04189723304750020218"
     },
     "user_tz": 300
    },
    "id": "B0wm3Ua1z2QO",
    "outputId": "b06e8f16-e7dc-4dbf-dc79-2933e5974e8b"
   },
   "outputs": [],
   "source": [
    "daylight_df.to_csv(PATH + 'daylight.csv', index_label='State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM6-KoAct6q6"
   },
   "source": [
    "## Record Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "error",
     "timestamp": 1739725297594,
     "user": {
      "displayName": "Peter King",
      "userId": "04189723304750020218"
     },
     "user_tz": 300
    },
    "id": "oWsjwzmfJxJB",
    "outputId": "d0b56543-804d-463c-e4f6-507b35263758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-02-16T18:10:57.617775+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.11\n",
      "IPython version      : 8.17.2\n",
      "\n",
      "Compiler    : GCC 11.3.0\n",
      "OS          : Linux\n",
      "Release     : 6.5.0-1020-aws\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "re      : 2.2.1\n",
      "json    : 2.0.9\n",
      "requests: 2.31.0\n",
      "pandas  : 2.0.2\n",
      "numpy   : 1.24.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMVEKJPxP1fNt4czOcxirQm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
